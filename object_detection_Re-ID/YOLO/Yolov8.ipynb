{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "278221b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 1: 5 person(s) detected | Inference time: 1401.46 ms\n",
      "Frame 2: 5 person(s) detected | Inference time: 13.34 ms\n",
      "Frame 3: 5 person(s) detected | Inference time: 10.23 ms\n",
      "Frame 4: 5 person(s) detected | Inference time: 9.97 ms\n",
      "Frame 5: 5 person(s) detected | Inference time: 12.08 ms\n",
      "Frame 6: 5 person(s) detected | Inference time: 11.12 ms\n",
      "Frame 7: 5 person(s) detected | Inference time: 10.84 ms\n",
      "Frame 8: 5 person(s) detected | Inference time: 11.97 ms\n",
      "Frame 9: 5 person(s) detected | Inference time: 10.79 ms\n",
      "Frame 10: 5 person(s) detected | Inference time: 10.84 ms\n",
      "Frame 11: 4 person(s) detected | Inference time: 11.32 ms\n",
      "Frame 12: 4 person(s) detected | Inference time: 12.35 ms\n",
      "Frame 13: 5 person(s) detected | Inference time: 18.44 ms\n",
      "Frame 14: 5 person(s) detected | Inference time: 14.37 ms\n",
      "Frame 15: 5 person(s) detected | Inference time: 11.20 ms\n",
      "Frame 16: 5 person(s) detected | Inference time: 10.12 ms\n",
      "Frame 17: 5 person(s) detected | Inference time: 15.47 ms\n",
      "Frame 18: 5 person(s) detected | Inference time: 10.71 ms\n",
      "Frame 19: 5 person(s) detected | Inference time: 10.13 ms\n",
      "Frame 20: 5 person(s) detected | Inference time: 12.43 ms\n",
      "Frame 21: 5 person(s) detected | Inference time: 10.48 ms\n",
      "Frame 22: 5 person(s) detected | Inference time: 12.50 ms\n",
      "Frame 23: 5 person(s) detected | Inference time: 11.56 ms\n",
      "Frame 24: 5 person(s) detected | Inference time: 13.07 ms\n",
      "Frame 25: 5 person(s) detected | Inference time: 12.90 ms\n",
      "Frame 26: 5 person(s) detected | Inference time: 9.97 ms\n",
      "Frame 27: 5 person(s) detected | Inference time: 11.81 ms\n",
      "Frame 28: 6 person(s) detected | Inference time: 11.42 ms\n",
      "Frame 29: 5 person(s) detected | Inference time: 9.99 ms\n",
      "Frame 30: 4 person(s) detected | Inference time: 12.00 ms\n",
      "Frame 31: 4 person(s) detected | Inference time: 12.23 ms\n",
      "Frame 32: 4 person(s) detected | Inference time: 13.17 ms\n",
      "Frame 33: 4 person(s) detected | Inference time: 13.90 ms\n",
      "Frame 34: 5 person(s) detected | Inference time: 13.56 ms\n",
      "Frame 35: 5 person(s) detected | Inference time: 9.44 ms\n",
      "Frame 36: 5 person(s) detected | Inference time: 11.51 ms\n",
      "Frame 37: 5 person(s) detected | Inference time: 11.35 ms\n",
      "Frame 38: 5 person(s) detected | Inference time: 9.87 ms\n",
      "Frame 39: 5 person(s) detected | Inference time: 11.31 ms\n",
      "Frame 40: 5 person(s) detected | Inference time: 9.57 ms\n",
      "Frame 41: 5 person(s) detected | Inference time: 11.86 ms\n",
      "Frame 42: 6 person(s) detected | Inference time: 11.34 ms\n",
      "Frame 43: 5 person(s) detected | Inference time: 10.08 ms\n",
      "Frame 44: 4 person(s) detected | Inference time: 10.84 ms\n",
      "Frame 45: 4 person(s) detected | Inference time: 12.76 ms\n",
      "Frame 46: 4 person(s) detected | Inference time: 10.07 ms\n",
      "Frame 47: 4 person(s) detected | Inference time: 11.75 ms\n",
      "Frame 48: 4 person(s) detected | Inference time: 10.03 ms\n",
      "Frame 49: 4 person(s) detected | Inference time: 10.09 ms\n",
      "Frame 50: 4 person(s) detected | Inference time: 10.77 ms\n",
      "Frame 51: 4 person(s) detected | Inference time: 12.13 ms\n",
      "Frame 52: 4 person(s) detected | Inference time: 14.44 ms\n",
      "Frame 53: 4 person(s) detected | Inference time: 10.75 ms\n",
      "Frame 54: 6 person(s) detected | Inference time: 10.31 ms\n",
      "Frame 55: 6 person(s) detected | Inference time: 10.21 ms\n",
      "Frame 56: 5 person(s) detected | Inference time: 10.51 ms\n",
      "Frame 57: 5 person(s) detected | Inference time: 10.92 ms\n",
      "Frame 58: 5 person(s) detected | Inference time: 18.92 ms\n",
      "Frame 59: 5 person(s) detected | Inference time: 19.90 ms\n",
      "Frame 60: 5 person(s) detected | Inference time: 14.03 ms\n",
      "Frame 61: 5 person(s) detected | Inference time: 11.01 ms\n",
      "Frame 62: 5 person(s) detected | Inference time: 12.08 ms\n",
      "Frame 63: 5 person(s) detected | Inference time: 13.66 ms\n",
      "Frame 64: 5 person(s) detected | Inference time: 10.91 ms\n",
      "Frame 65: 5 person(s) detected | Inference time: 13.20 ms\n",
      "Frame 66: 5 person(s) detected | Inference time: 13.30 ms\n",
      "Frame 67: 6 person(s) detected | Inference time: 9.80 ms\n",
      "Frame 68: 5 person(s) detected | Inference time: 11.10 ms\n",
      "Frame 69: 4 person(s) detected | Inference time: 12.34 ms\n",
      "Frame 70: 4 person(s) detected | Inference time: 10.46 ms\n",
      "Frame 71: 4 person(s) detected | Inference time: 15.84 ms\n",
      "Frame 72: 4 person(s) detected | Inference time: 15.01 ms\n",
      "Frame 73: 4 person(s) detected | Inference time: 14.49 ms\n",
      "Frame 74: 4 person(s) detected | Inference time: 10.36 ms\n",
      "Frame 75: 5 person(s) detected | Inference time: 14.55 ms\n",
      "Frame 76: 5 person(s) detected | Inference time: 10.58 ms\n",
      "Frame 77: 5 person(s) detected | Inference time: 12.86 ms\n",
      "Frame 78: 5 person(s) detected | Inference time: 15.36 ms\n",
      "Frame 79: 5 person(s) detected | Inference time: 12.81 ms\n",
      "Frame 80: 5 person(s) detected | Inference time: 11.43 ms\n",
      "Frame 81: 4 person(s) detected | Inference time: 12.59 ms\n",
      "Frame 82: 6 person(s) detected | Inference time: 13.29 ms\n",
      "Frame 83: 6 person(s) detected | Inference time: 9.75 ms\n",
      "Frame 84: 6 person(s) detected | Inference time: 13.66 ms\n",
      "Frame 85: 6 person(s) detected | Inference time: 13.85 ms\n",
      "Frame 86: 6 person(s) detected | Inference time: 13.52 ms\n",
      "Frame 87: 6 person(s) detected | Inference time: 15.69 ms\n",
      "Frame 88: 6 person(s) detected | Inference time: 19.81 ms\n",
      "Frame 89: 6 person(s) detected | Inference time: 16.81 ms\n",
      "Frame 90: 6 person(s) detected | Inference time: 14.04 ms\n",
      "Frame 91: 6 person(s) detected | Inference time: 14.16 ms\n",
      "Frame 92: 6 person(s) detected | Inference time: 11.37 ms\n",
      "Frame 93: 5 person(s) detected | Inference time: 14.53 ms\n",
      "Frame 94: 5 person(s) detected | Inference time: 12.45 ms\n",
      "Frame 95: 6 person(s) detected | Inference time: 12.82 ms\n",
      "Frame 96: 6 person(s) detected | Inference time: 13.13 ms\n",
      "Frame 97: 6 person(s) detected | Inference time: 15.78 ms\n",
      "Frame 98: 5 person(s) detected | Inference time: 10.51 ms\n",
      "Frame 99: 5 person(s) detected | Inference time: 10.01 ms\n",
      "Frame 100: 5 person(s) detected | Inference time: 10.89 ms\n",
      "Frame 101: 5 person(s) detected | Inference time: 10.67 ms\n",
      "Frame 102: 5 person(s) detected | Inference time: 12.90 ms\n",
      "Frame 103: 4 person(s) detected | Inference time: 13.12 ms\n",
      "Frame 104: 5 person(s) detected | Inference time: 12.01 ms\n",
      "Frame 105: 4 person(s) detected | Inference time: 15.47 ms\n",
      "Frame 106: 5 person(s) detected | Inference time: 14.26 ms\n",
      "Frame 107: 4 person(s) detected | Inference time: 12.93 ms\n",
      "Frame 108: 6 person(s) detected | Inference time: 16.83 ms\n",
      "Frame 109: 6 person(s) detected | Inference time: 14.88 ms\n",
      "Frame 110: 6 person(s) detected | Inference time: 12.51 ms\n",
      "Frame 111: 5 person(s) detected | Inference time: 13.95 ms\n",
      "Frame 112: 5 person(s) detected | Inference time: 13.42 ms\n",
      "Frame 113: 5 person(s) detected | Inference time: 11.65 ms\n",
      "Frame 114: 5 person(s) detected | Inference time: 10.27 ms\n",
      "Frame 115: 5 person(s) detected | Inference time: 10.19 ms\n",
      "Frame 116: 5 person(s) detected | Inference time: 13.74 ms\n",
      "Frame 117: 5 person(s) detected | Inference time: 11.33 ms\n",
      "Frame 118: 5 person(s) detected | Inference time: 12.38 ms\n",
      "Frame 119: 5 person(s) detected | Inference time: 16.06 ms\n",
      "Frame 120: 5 person(s) detected | Inference time: 16.92 ms\n",
      "Frame 121: 5 person(s) detected | Inference time: 14.63 ms\n",
      "Frame 122: 5 person(s) detected | Inference time: 14.53 ms\n",
      "Frame 123: 5 person(s) detected | Inference time: 12.41 ms\n",
      "Frame 124: 3 person(s) detected | Inference time: 14.10 ms\n",
      "Frame 125: 3 person(s) detected | Inference time: 12.78 ms\n",
      "Frame 126: 3 person(s) detected | Inference time: 9.92 ms\n",
      "Frame 127: 3 person(s) detected | Inference time: 9.91 ms\n",
      "Frame 128: 3 person(s) detected | Inference time: 11.77 ms\n",
      "Frame 129: 3 person(s) detected | Inference time: 13.30 ms\n",
      "Frame 130: 3 person(s) detected | Inference time: 13.08 ms\n",
      "Frame 131: 4 person(s) detected | Inference time: 12.38 ms\n",
      "Frame 132: 4 person(s) detected | Inference time: 16.07 ms\n",
      "Frame 133: 5 person(s) detected | Inference time: 18.64 ms\n",
      "Frame 134: 5 person(s) detected | Inference time: 15.63 ms\n",
      "Frame 135: 5 person(s) detected | Inference time: 9.36 ms\n",
      "Frame 136: 5 person(s) detected | Inference time: 10.14 ms\n",
      "Frame 137: 5 person(s) detected | Inference time: 11.99 ms\n",
      "Frame 138: 5 person(s) detected | Inference time: 10.06 ms\n",
      "Frame 139: 5 person(s) detected | Inference time: 12.55 ms\n",
      "Frame 140: 5 person(s) detected | Inference time: 13.95 ms\n",
      "Frame 141: 5 person(s) detected | Inference time: 13.55 ms\n",
      "Frame 142: 5 person(s) detected | Inference time: 12.50 ms\n",
      "Frame 143: 5 person(s) detected | Inference time: 13.51 ms\n",
      "Frame 144: 5 person(s) detected | Inference time: 12.55 ms\n",
      "Frame 145: 5 person(s) detected | Inference time: 15.09 ms\n",
      "Frame 146: 4 person(s) detected | Inference time: 13.05 ms\n",
      "Frame 147: 4 person(s) detected | Inference time: 12.74 ms\n",
      "Frame 148: 4 person(s) detected | Inference time: 16.14 ms\n",
      "Frame 149: 4 person(s) detected | Inference time: 20.09 ms\n",
      "Frame 150: 4 person(s) detected | Inference time: 13.45 ms\n",
      "Frame 151: 4 person(s) detected | Inference time: 14.24 ms\n",
      "Frame 152: 4 person(s) detected | Inference time: 14.44 ms\n",
      "Frame 153: 5 person(s) detected | Inference time: 13.32 ms\n",
      "Frame 154: 5 person(s) detected | Inference time: 11.08 ms\n",
      "Frame 155: 6 person(s) detected | Inference time: 12.96 ms\n",
      "Frame 156: 6 person(s) detected | Inference time: 14.49 ms\n",
      "Frame 157: 5 person(s) detected | Inference time: 15.59 ms\n",
      "Frame 158: 5 person(s) detected | Inference time: 13.12 ms\n",
      "Frame 159: 5 person(s) detected | Inference time: 12.31 ms\n",
      "Frame 160: 5 person(s) detected | Inference time: 13.92 ms\n",
      "Frame 161: 6 person(s) detected | Inference time: 11.12 ms\n",
      "Frame 162: 4 person(s) detected | Inference time: 12.82 ms\n",
      "Frame 163: 4 person(s) detected | Inference time: 14.55 ms\n",
      "Frame 164: 4 person(s) detected | Inference time: 10.09 ms\n",
      "Frame 165: 4 person(s) detected | Inference time: 14.75 ms\n",
      "Frame 166: 4 person(s) detected | Inference time: 20.20 ms\n",
      "Frame 167: 4 person(s) detected | Inference time: 12.29 ms\n",
      "Frame 168: 4 person(s) detected | Inference time: 13.01 ms\n",
      "Frame 169: 4 person(s) detected | Inference time: 13.64 ms\n",
      "Frame 170: 4 person(s) detected | Inference time: 13.07 ms\n",
      "Frame 171: 4 person(s) detected | Inference time: 14.62 ms\n",
      "Frame 172: 4 person(s) detected | Inference time: 10.99 ms\n",
      "Frame 173: 4 person(s) detected | Inference time: 18.79 ms\n",
      "Frame 174: 4 person(s) detected | Inference time: 13.98 ms\n",
      "Frame 175: 4 person(s) detected | Inference time: 12.64 ms\n",
      "Frame 176: 4 person(s) detected | Inference time: 17.28 ms\n",
      "Frame 177: 4 person(s) detected | Inference time: 16.75 ms\n",
      "Frame 178: 4 person(s) detected | Inference time: 11.00 ms\n",
      "Frame 179: 4 person(s) detected | Inference time: 13.49 ms\n",
      "Frame 180: 5 person(s) detected | Inference time: 12.68 ms\n",
      "Frame 181: 5 person(s) detected | Inference time: 11.80 ms\n",
      "Frame 182: 5 person(s) detected | Inference time: 13.31 ms\n",
      "Frame 183: 5 person(s) detected | Inference time: 13.70 ms\n",
      "Frame 184: 5 person(s) detected | Inference time: 14.41 ms\n",
      "Frame 185: 5 person(s) detected | Inference time: 10.90 ms\n",
      "Frame 186: 4 person(s) detected | Inference time: 13.44 ms\n",
      "Frame 187: 5 person(s) detected | Inference time: 16.46 ms\n",
      "Frame 188: 5 person(s) detected | Inference time: 18.11 ms\n",
      "Frame 189: 5 person(s) detected | Inference time: 13.80 ms\n",
      "Frame 190: 5 person(s) detected | Inference time: 15.04 ms\n",
      "Frame 191: 5 person(s) detected | Inference time: 10.81 ms\n",
      "Frame 192: 5 person(s) detected | Inference time: 12.06 ms\n",
      "Frame 193: 5 person(s) detected | Inference time: 16.44 ms\n",
      "Frame 194: 5 person(s) detected | Inference time: 17.59 ms\n",
      "Frame 195: 5 person(s) detected | Inference time: 13.98 ms\n",
      "Frame 196: 6 person(s) detected | Inference time: 15.03 ms\n",
      "Frame 197: 5 person(s) detected | Inference time: 10.76 ms\n",
      "Frame 198: 6 person(s) detected | Inference time: 14.85 ms\n",
      "Frame 199: 5 person(s) detected | Inference time: 13.98 ms\n",
      "Frame 200: 5 person(s) detected | Inference time: 19.88 ms\n",
      "Frame 201: 5 person(s) detected | Inference time: 14.55 ms\n",
      "Frame 202: 5 person(s) detected | Inference time: 14.20 ms\n",
      "Frame 203: 6 person(s) detected | Inference time: 14.92 ms\n",
      "Frame 204: 6 person(s) detected | Inference time: 13.61 ms\n",
      "Frame 205: 6 person(s) detected | Inference time: 14.73 ms\n",
      "Frame 206: 5 person(s) detected | Inference time: 18.52 ms\n",
      "Frame 207: 5 person(s) detected | Inference time: 17.98 ms\n",
      "Frame 208: 5 person(s) detected | Inference time: 12.78 ms\n",
      "Frame 209: 5 person(s) detected | Inference time: 12.75 ms\n",
      "Frame 210: 5 person(s) detected | Inference time: 13.33 ms\n",
      "Frame 211: 5 person(s) detected | Inference time: 14.90 ms\n",
      "Frame 212: 5 person(s) detected | Inference time: 18.67 ms\n",
      "Frame 213: 5 person(s) detected | Inference time: 16.52 ms\n",
      "Frame 214: 5 person(s) detected | Inference time: 15.50 ms\n",
      "Frame 215: 5 person(s) detected | Inference time: 12.51 ms\n",
      "Frame 216: 6 person(s) detected | Inference time: 13.73 ms\n",
      "Frame 217: 6 person(s) detected | Inference time: 11.66 ms\n",
      "Frame 218: 5 person(s) detected | Inference time: 14.31 ms\n",
      "Frame 219: 5 person(s) detected | Inference time: 13.94 ms\n",
      "Frame 220: 5 person(s) detected | Inference time: 17.74 ms\n",
      "Frame 221: 5 person(s) detected | Inference time: 12.12 ms\n",
      "Frame 222: 5 person(s) detected | Inference time: 13.49 ms\n",
      "Frame 223: 5 person(s) detected | Inference time: 13.08 ms\n",
      "Frame 224: 6 person(s) detected | Inference time: 14.51 ms\n",
      "Frame 225: 5 person(s) detected | Inference time: 14.23 ms\n",
      "Frame 226: 6 person(s) detected | Inference time: 11.48 ms\n",
      "Frame 227: 6 person(s) detected | Inference time: 14.90 ms\n",
      "Frame 228: 6 person(s) detected | Inference time: 20.78 ms\n",
      "Frame 229: 6 person(s) detected | Inference time: 15.96 ms\n",
      "Frame 230: 6 person(s) detected | Inference time: 12.05 ms\n",
      "Frame 231: 6 person(s) detected | Inference time: 12.94 ms\n",
      "Frame 232: 6 person(s) detected | Inference time: 13.07 ms\n",
      "Frame 233: 6 person(s) detected | Inference time: 13.12 ms\n",
      "Frame 234: 6 person(s) detected | Inference time: 12.29 ms\n",
      "Frame 235: 6 person(s) detected | Inference time: 17.91 ms\n",
      "Frame 236: 6 person(s) detected | Inference time: 20.00 ms\n",
      "Frame 237: 5 person(s) detected | Inference time: 14.58 ms\n",
      "Frame 238: 5 person(s) detected | Inference time: 11.24 ms\n",
      "Frame 239: 5 person(s) detected | Inference time: 13.93 ms\n",
      "Frame 240: 5 person(s) detected | Inference time: 14.17 ms\n",
      "Frame 241: 5 person(s) detected | Inference time: 12.60 ms\n",
      "Frame 242: 5 person(s) detected | Inference time: 14.21 ms\n",
      "Frame 243: 5 person(s) detected | Inference time: 15.10 ms\n",
      "Frame 244: 5 person(s) detected | Inference time: 15.64 ms\n",
      "Frame 245: 4 person(s) detected | Inference time: 15.46 ms\n",
      "Frame 246: 5 person(s) detected | Inference time: 14.60 ms\n",
      "Frame 247: 4 person(s) detected | Inference time: 18.12 ms\n",
      "Frame 248: 4 person(s) detected | Inference time: 16.20 ms\n",
      "Frame 249: 3 person(s) detected | Inference time: 13.83 ms\n",
      "Frame 250: 3 person(s) detected | Inference time: 12.91 ms\n",
      "Frame 251: 3 person(s) detected | Inference time: 12.08 ms\n",
      "Frame 252: 3 person(s) detected | Inference time: 12.93 ms\n",
      "Frame 253: 3 person(s) detected | Inference time: 11.19 ms\n",
      "Frame 254: 3 person(s) detected | Inference time: 13.23 ms\n",
      "Frame 255: 4 person(s) detected | Inference time: 14.82 ms\n",
      "Frame 256: 4 person(s) detected | Inference time: 20.62 ms\n",
      "Frame 257: 5 person(s) detected | Inference time: 20.27 ms\n",
      "Frame 258: 4 person(s) detected | Inference time: 14.55 ms\n",
      "Frame 259: 4 person(s) detected | Inference time: 12.08 ms\n",
      "Frame 260: 4 person(s) detected | Inference time: 16.34 ms\n",
      "Frame 261: 5 person(s) detected | Inference time: 16.46 ms\n",
      "Frame 262: 5 person(s) detected | Inference time: 18.25 ms\n",
      "Frame 263: 5 person(s) detected | Inference time: 11.84 ms\n",
      "Frame 264: 5 person(s) detected | Inference time: 11.21 ms\n",
      "Frame 265: 4 person(s) detected | Inference time: 13.04 ms\n",
      "Frame 266: 4 person(s) detected | Inference time: 11.93 ms\n",
      "Frame 267: 5 person(s) detected | Inference time: 11.36 ms\n",
      "Frame 268: 5 person(s) detected | Inference time: 11.52 ms\n",
      "Frame 269: 5 person(s) detected | Inference time: 12.27 ms\n",
      "Frame 270: 5 person(s) detected | Inference time: 20.36 ms\n",
      "Frame 271: 5 person(s) detected | Inference time: 15.61 ms\n",
      "Frame 272: 5 person(s) detected | Inference time: 15.82 ms\n",
      "Frame 273: 5 person(s) detected | Inference time: 12.49 ms\n",
      "Frame 274: 4 person(s) detected | Inference time: 13.68 ms\n",
      "Frame 275: 4 person(s) detected | Inference time: 14.30 ms\n",
      "Frame 276: 3 person(s) detected | Inference time: 15.02 ms\n",
      "Frame 277: 3 person(s) detected | Inference time: 16.29 ms\n",
      "Frame 278: 3 person(s) detected | Inference time: 17.15 ms\n",
      "Frame 279: 3 person(s) detected | Inference time: 12.54 ms\n",
      "Frame 280: 3 person(s) detected | Inference time: 11.29 ms\n",
      "Frame 281: 3 person(s) detected | Inference time: 12.53 ms\n",
      "Frame 282: 3 person(s) detected | Inference time: 12.04 ms\n",
      "Frame 283: 3 person(s) detected | Inference time: 14.74 ms\n",
      "Frame 284: 4 person(s) detected | Inference time: 12.83 ms\n",
      "Frame 285: 4 person(s) detected | Inference time: 12.78 ms\n",
      "Frame 286: 4 person(s) detected | Inference time: 13.19 ms\n",
      "Frame 287: 4 person(s) detected | Inference time: 17.44 ms\n",
      "Frame 288: 3 person(s) detected | Inference time: 14.46 ms\n",
      "Frame 289: 3 person(s) detected | Inference time: 18.22 ms\n",
      "Frame 290: 3 person(s) detected | Inference time: 18.28 ms\n",
      "Frame 291: 3 person(s) detected | Inference time: 18.34 ms\n",
      "Frame 292: 4 person(s) detected | Inference time: 14.30 ms\n",
      "Frame 293: 4 person(s) detected | Inference time: 14.79 ms\n",
      "Frame 294: 4 person(s) detected | Inference time: 16.85 ms\n",
      "Frame 295: 4 person(s) detected | Inference time: 17.13 ms\n",
      "Frame 296: 4 person(s) detected | Inference time: 12.32 ms\n",
      "Frame 297: 4 person(s) detected | Inference time: 11.24 ms\n",
      "Frame 298: 4 person(s) detected | Inference time: 13.15 ms\n",
      "Frame 299: 4 person(s) detected | Inference time: 13.47 ms\n",
      "Frame 300: 4 person(s) detected | Inference time: 17.15 ms\n",
      "Frame 301: 4 person(s) detected | Inference time: 12.81 ms\n",
      "Frame 302: 4 person(s) detected | Inference time: 12.86 ms\n",
      "Frame 303: 4 person(s) detected | Inference time: 14.61 ms\n",
      "Frame 304: 4 person(s) detected | Inference time: 18.67 ms\n",
      "Frame 305: 5 person(s) detected | Inference time: 12.96 ms\n",
      "Frame 306: 5 person(s) detected | Inference time: 13.84 ms\n",
      "Frame 307: 5 person(s) detected | Inference time: 18.12 ms\n",
      "Frame 308: 5 person(s) detected | Inference time: 14.08 ms\n",
      "Frame 309: 6 person(s) detected | Inference time: 16.54 ms\n",
      "Frame 310: 5 person(s) detected | Inference time: 13.20 ms\n",
      "Frame 311: 5 person(s) detected | Inference time: 13.39 ms\n",
      "Frame 312: 5 person(s) detected | Inference time: 14.63 ms\n",
      "Frame 313: 5 person(s) detected | Inference time: 13.20 ms\n",
      "Frame 314: 5 person(s) detected | Inference time: 13.94 ms\n",
      "Frame 315: 5 person(s) detected | Inference time: 16.35 ms\n",
      "Frame 316: 5 person(s) detected | Inference time: 17.67 ms\n",
      "Frame 317: 5 person(s) detected | Inference time: 16.91 ms\n",
      "Frame 318: 5 person(s) detected | Inference time: 15.99 ms\n",
      "Frame 319: 5 person(s) detected | Inference time: 14.71 ms\n",
      "Frame 320: 5 person(s) detected | Inference time: 17.01 ms\n",
      "Frame 321: 5 person(s) detected | Inference time: 20.54 ms\n",
      "Frame 322: 5 person(s) detected | Inference time: 14.37 ms\n",
      "Frame 323: 5 person(s) detected | Inference time: 15.77 ms\n",
      "Frame 324: 5 person(s) detected | Inference time: 11.80 ms\n",
      "Frame 325: 5 person(s) detected | Inference time: 13.98 ms\n",
      "Frame 326: 5 person(s) detected | Inference time: 14.44 ms\n",
      "Frame 327: 5 person(s) detected | Inference time: 14.46 ms\n",
      "Frame 328: 4 person(s) detected | Inference time: 12.76 ms\n",
      "Frame 329: 4 person(s) detected | Inference time: 21.15 ms\n",
      "Frame 330: 4 person(s) detected | Inference time: 14.51 ms\n",
      "Frame 331: 4 person(s) detected | Inference time: 14.27 ms\n",
      "Frame 332: 4 person(s) detected | Inference time: 13.50 ms\n",
      "Frame 333: 4 person(s) detected | Inference time: 15.80 ms\n",
      "Frame 334: 4 person(s) detected | Inference time: 21.51 ms\n",
      "Frame 335: 4 person(s) detected | Inference time: 17.96 ms\n",
      "Frame 336: 4 person(s) detected | Inference time: 19.49 ms\n",
      "Frame 337: 4 person(s) detected | Inference time: 13.31 ms\n",
      "Frame 338: 5 person(s) detected | Inference time: 13.03 ms\n",
      "Frame 339: 5 person(s) detected | Inference time: 12.98 ms\n",
      "Frame 340: 5 person(s) detected | Inference time: 13.11 ms\n",
      "Frame 341: 6 person(s) detected | Inference time: 16.25 ms\n",
      "Frame 342: 6 person(s) detected | Inference time: 17.65 ms\n",
      "Frame 343: 6 person(s) detected | Inference time: 12.91 ms\n",
      "Frame 344: 7 person(s) detected | Inference time: 13.61 ms\n",
      "Frame 345: 7 person(s) detected | Inference time: 14.67 ms\n",
      "Frame 346: 7 person(s) detected | Inference time: 15.28 ms\n",
      "Frame 347: 7 person(s) detected | Inference time: 12.20 ms\n",
      "Frame 348: 7 person(s) detected | Inference time: 12.34 ms\n",
      "Frame 349: 7 person(s) detected | Inference time: 12.55 ms\n",
      "Frame 350: 7 person(s) detected | Inference time: 11.47 ms\n",
      "Frame 351: 6 person(s) detected | Inference time: 12.96 ms\n",
      "Frame 352: 6 person(s) detected | Inference time: 12.63 ms\n",
      "Frame 353: 6 person(s) detected | Inference time: 14.53 ms\n",
      "Frame 354: 6 person(s) detected | Inference time: 16.95 ms\n",
      "Frame 355: 6 person(s) detected | Inference time: 17.46 ms\n",
      "Frame 356: 6 person(s) detected | Inference time: 15.43 ms\n",
      "Frame 357: 6 person(s) detected | Inference time: 11.55 ms\n",
      "Frame 358: 5 person(s) detected | Inference time: 13.22 ms\n",
      "Frame 359: 5 person(s) detected | Inference time: 14.90 ms\n",
      "Frame 360: 5 person(s) detected | Inference time: 14.66 ms\n",
      "Frame 361: 5 person(s) detected | Inference time: 13.80 ms\n",
      "Frame 362: 6 person(s) detected | Inference time: 14.66 ms\n",
      "Frame 363: 4 person(s) detected | Inference time: 17.61 ms\n",
      "Frame 364: 4 person(s) detected | Inference time: 18.52 ms\n",
      "Frame 365: 4 person(s) detected | Inference time: 21.51 ms\n",
      "Frame 366: 4 person(s) detected | Inference time: 14.74 ms\n",
      "Frame 367: 3 person(s) detected | Inference time: 14.82 ms\n",
      "Frame 368: 3 person(s) detected | Inference time: 15.76 ms\n",
      "Frame 369: 3 person(s) detected | Inference time: 16.93 ms\n",
      "Frame 370: 3 person(s) detected | Inference time: 19.03 ms\n",
      "Frame 371: 3 person(s) detected | Inference time: 13.99 ms\n",
      "Frame 372: 4 person(s) detected | Inference time: 13.22 ms\n",
      "Frame 373: 4 person(s) detected | Inference time: 14.45 ms\n",
      "Frame 374: 4 person(s) detected | Inference time: 14.26 ms\n",
      "Frame 375: 4 person(s) detected | Inference time: 12.31 ms\n",
      "Frame 376: 5 person(s) detected | Inference time: 11.85 ms\n",
      "Frame 377: 5 person(s) detected | Inference time: 13.63 ms\n",
      "Frame 378: 5 person(s) detected | Inference time: 12.10 ms\n",
      "Frame 379: 6 person(s) detected | Inference time: 17.49 ms\n",
      "Frame 380: 6 person(s) detected | Inference time: 14.67 ms\n",
      "Frame 381: 7 person(s) detected | Inference time: 11.42 ms\n",
      "Frame 382: 7 person(s) detected | Inference time: 13.69 ms\n",
      "Frame 383: 5 person(s) detected | Inference time: 12.43 ms\n",
      "Frame 384: 6 person(s) detected | Inference time: 11.40 ms\n",
      "Frame 385: 7 person(s) detected | Inference time: 14.52 ms\n",
      "Frame 386: 7 person(s) detected | Inference time: 13.67 ms\n",
      "Frame 387: 6 person(s) detected | Inference time: 19.03 ms\n",
      "Frame 388: 6 person(s) detected | Inference time: 13.16 ms\n",
      "Frame 389: 6 person(s) detected | Inference time: 13.48 ms\n",
      "Frame 390: 6 person(s) detected | Inference time: 13.35 ms\n",
      "Frame 391: 5 person(s) detected | Inference time: 13.35 ms\n",
      "Frame 392: 5 person(s) detected | Inference time: 12.23 ms\n",
      "Frame 393: 5 person(s) detected | Inference time: 12.48 ms\n",
      "Frame 394: 5 person(s) detected | Inference time: 15.98 ms\n",
      "Frame 395: 5 person(s) detected | Inference time: 15.24 ms\n",
      "Frame 396: 5 person(s) detected | Inference time: 13.82 ms\n",
      "Frame 397: 5 person(s) detected | Inference time: 10.57 ms\n",
      "Frame 398: 5 person(s) detected | Inference time: 12.47 ms\n",
      "Frame 399: 5 person(s) detected | Inference time: 11.52 ms\n",
      "Frame 400: 5 person(s) detected | Inference time: 9.84 ms\n",
      "Frame 401: 5 person(s) detected | Inference time: 14.64 ms\n",
      "Frame 402: 5 person(s) detected | Inference time: 10.24 ms\n",
      "Frame 403: 5 person(s) detected | Inference time: 13.31 ms\n",
      "Frame 404: 4 person(s) detected | Inference time: 15.12 ms\n",
      "Frame 405: 4 person(s) detected | Inference time: 14.26 ms\n",
      "Frame 406: 5 person(s) detected | Inference time: 11.12 ms\n",
      "Frame 407: 5 person(s) detected | Inference time: 13.69 ms\n",
      "Frame 408: 5 person(s) detected | Inference time: 10.64 ms\n",
      "Frame 409: 5 person(s) detected | Inference time: 11.59 ms\n",
      "Frame 410: 5 person(s) detected | Inference time: 10.88 ms\n",
      "Frame 411: 5 person(s) detected | Inference time: 12.18 ms\n",
      "Frame 412: 5 person(s) detected | Inference time: 16.55 ms\n",
      "Frame 413: 6 person(s) detected | Inference time: 13.48 ms\n",
      "Frame 414: 6 person(s) detected | Inference time: 14.25 ms\n",
      "Frame 415: 6 person(s) detected | Inference time: 17.96 ms\n",
      "Frame 416: 6 person(s) detected | Inference time: 11.46 ms\n",
      "Frame 417: 6 person(s) detected | Inference time: 10.92 ms\n",
      "Frame 418: 6 person(s) detected | Inference time: 8.67 ms\n",
      "Frame 419: 6 person(s) detected | Inference time: 11.59 ms\n",
      "Frame 420: 6 person(s) detected | Inference time: 16.97 ms\n",
      "Frame 421: 6 person(s) detected | Inference time: 11.65 ms\n",
      "Frame 422: 6 person(s) detected | Inference time: 11.46 ms\n",
      "Frame 423: 5 person(s) detected | Inference time: 10.87 ms\n",
      "Frame 424: 6 person(s) detected | Inference time: 12.10 ms\n",
      "Frame 425: 6 person(s) detected | Inference time: 12.38 ms\n",
      "Frame 426: 6 person(s) detected | Inference time: 12.62 ms\n",
      "Frame 427: 5 person(s) detected | Inference time: 12.88 ms\n",
      "Frame 428: 5 person(s) detected | Inference time: 15.82 ms\n",
      "Frame 429: 5 person(s) detected | Inference time: 14.74 ms\n",
      "Frame 430: 6 person(s) detected | Inference time: 11.28 ms\n",
      "Frame 431: 5 person(s) detected | Inference time: 11.19 ms\n",
      "Frame 432: 6 person(s) detected | Inference time: 11.16 ms\n",
      "Frame 433: 6 person(s) detected | Inference time: 11.95 ms\n",
      "Frame 434: 6 person(s) detected | Inference time: 11.70 ms\n",
      "Frame 435: 6 person(s) detected | Inference time: 12.69 ms\n",
      "Frame 436: 6 person(s) detected | Inference time: 12.90 ms\n",
      "Frame 437: 6 person(s) detected | Inference time: 11.72 ms\n",
      "Frame 438: 5 person(s) detected | Inference time: 11.47 ms\n",
      "Frame 439: 5 person(s) detected | Inference time: 13.01 ms\n",
      "Frame 440: 6 person(s) detected | Inference time: 18.04 ms\n",
      "Frame 441: 6 person(s) detected | Inference time: 17.72 ms\n",
      "Frame 442: 6 person(s) detected | Inference time: 13.96 ms\n",
      "Frame 443: 4 person(s) detected | Inference time: 12.14 ms\n",
      "Frame 444: 4 person(s) detected | Inference time: 13.98 ms\n",
      "Frame 445: 4 person(s) detected | Inference time: 11.62 ms\n",
      "Frame 446: 5 person(s) detected | Inference time: 10.74 ms\n",
      "Frame 447: 4 person(s) detected | Inference time: 13.01 ms\n",
      "Frame 448: 4 person(s) detected | Inference time: 11.33 ms\n",
      "Frame 449: 5 person(s) detected | Inference time: 19.11 ms\n",
      "Frame 450: 5 person(s) detected | Inference time: 17.78 ms\n",
      "Frame 451: 4 person(s) detected | Inference time: 13.06 ms\n",
      "Frame 452: 5 person(s) detected | Inference time: 15.47 ms\n",
      "Frame 453: 4 person(s) detected | Inference time: 11.88 ms\n",
      "Frame 454: 4 person(s) detected | Inference time: 12.94 ms\n",
      "Frame 455: 4 person(s) detected | Inference time: 10.45 ms\n",
      "Frame 456: 5 person(s) detected | Inference time: 14.10 ms\n",
      "Frame 457: 6 person(s) detected | Inference time: 15.55 ms\n",
      "Frame 458: 6 person(s) detected | Inference time: 16.90 ms\n",
      "Frame 459: 6 person(s) detected | Inference time: 11.25 ms\n",
      "Frame 460: 6 person(s) detected | Inference time: 15.43 ms\n",
      "Frame 461: 5 person(s) detected | Inference time: 14.23 ms\n",
      "Frame 462: 5 person(s) detected | Inference time: 16.39 ms\n",
      "Frame 463: 5 person(s) detected | Inference time: 14.30 ms\n",
      "Frame 464: 5 person(s) detected | Inference time: 13.66 ms\n",
      "Frame 465: 4 person(s) detected | Inference time: 18.66 ms\n",
      "Frame 466: 5 person(s) detected | Inference time: 16.65 ms\n",
      "Frame 467: 5 person(s) detected | Inference time: 12.51 ms\n",
      "Frame 468: 5 person(s) detected | Inference time: 21.13 ms\n",
      "Frame 469: 5 person(s) detected | Inference time: 15.16 ms\n",
      "Frame 470: 5 person(s) detected | Inference time: 15.29 ms\n",
      "Frame 471: 6 person(s) detected | Inference time: 15.97 ms\n",
      "Frame 472: 6 person(s) detected | Inference time: 14.26 ms\n",
      "Frame 473: 6 person(s) detected | Inference time: 14.17 ms\n",
      "Frame 474: 6 person(s) detected | Inference time: 14.27 ms\n",
      "Frame 475: 6 person(s) detected | Inference time: 12.73 ms\n",
      "Frame 476: 5 person(s) detected | Inference time: 13.27 ms\n",
      "Frame 477: 5 person(s) detected | Inference time: 15.56 ms\n",
      "Frame 478: 6 person(s) detected | Inference time: 11.61 ms\n",
      "Frame 479: 5 person(s) detected | Inference time: 13.17 ms\n",
      "Frame 480: 5 person(s) detected | Inference time: 12.96 ms\n",
      "Frame 481: 5 person(s) detected | Inference time: 15.52 ms\n",
      "Frame 482: 5 person(s) detected | Inference time: 10.93 ms\n",
      "Frame 483: 5 person(s) detected | Inference time: 14.19 ms\n",
      "Frame 484: 5 person(s) detected | Inference time: 16.91 ms\n",
      "Frame 485: 5 person(s) detected | Inference time: 14.42 ms\n",
      "Frame 486: 5 person(s) detected | Inference time: 15.07 ms\n",
      "Frame 487: 5 person(s) detected | Inference time: 16.54 ms\n",
      "Frame 488: 6 person(s) detected | Inference time: 14.80 ms\n",
      "Frame 489: 6 person(s) detected | Inference time: 12.66 ms\n",
      "Frame 490: 5 person(s) detected | Inference time: 14.77 ms\n",
      "Frame 491: 5 person(s) detected | Inference time: 12.18 ms\n",
      "Frame 492: 5 person(s) detected | Inference time: 13.98 ms\n",
      "Frame 493: 5 person(s) detected | Inference time: 11.51 ms\n",
      "Frame 494: 5 person(s) detected | Inference time: 18.15 ms\n",
      "Frame 495: 5 person(s) detected | Inference time: 15.50 ms\n",
      "Frame 496: 5 person(s) detected | Inference time: 13.70 ms\n",
      "Frame 497: 5 person(s) detected | Inference time: 12.88 ms\n",
      "Frame 498: 4 person(s) detected | Inference time: 12.06 ms\n",
      "Frame 499: 4 person(s) detected | Inference time: 14.77 ms\n",
      "Frame 500: 4 person(s) detected | Inference time: 19.86 ms\n",
      "Frame 501: 4 person(s) detected | Inference time: 17.18 ms\n",
      "Frame 502: 4 person(s) detected | Inference time: 23.85 ms\n",
      "Frame 503: 4 person(s) detected | Inference time: 14.92 ms\n",
      "Frame 504: 4 person(s) detected | Inference time: 13.80 ms\n",
      "Frame 505: 4 person(s) detected | Inference time: 12.99 ms\n",
      "Frame 506: 4 person(s) detected | Inference time: 13.16 ms\n",
      "Frame 507: 4 person(s) detected | Inference time: 12.94 ms\n",
      "Frame 508: 4 person(s) detected | Inference time: 14.39 ms\n",
      "Frame 509: 4 person(s) detected | Inference time: 11.04 ms\n",
      "Frame 510: 4 person(s) detected | Inference time: 13.68 ms\n",
      "Frame 511: 4 person(s) detected | Inference time: 16.46 ms\n",
      "Frame 512: 5 person(s) detected | Inference time: 11.86 ms\n",
      "Frame 513: 6 person(s) detected | Inference time: 17.91 ms\n",
      "Frame 514: 6 person(s) detected | Inference time: 13.21 ms\n",
      "Frame 515: 5 person(s) detected | Inference time: 13.58 ms\n",
      "Frame 516: 5 person(s) detected | Inference time: 14.66 ms\n",
      "Frame 517: 5 person(s) detected | Inference time: 16.90 ms\n",
      "Frame 518: 5 person(s) detected | Inference time: 15.22 ms\n",
      "Frame 519: 5 person(s) detected | Inference time: 16.74 ms\n",
      "Frame 520: 5 person(s) detected | Inference time: 17.80 ms\n",
      "Frame 521: 5 person(s) detected | Inference time: 18.13 ms\n",
      "Frame 522: 5 person(s) detected | Inference time: 20.47 ms\n",
      "Frame 523: 4 person(s) detected | Inference time: 16.70 ms\n",
      "Frame 524: 5 person(s) detected | Inference time: 14.54 ms\n",
      "Frame 525: 6 person(s) detected | Inference time: 14.10 ms\n",
      "Frame 526: 5 person(s) detected | Inference time: 13.54 ms\n",
      "Frame 527: 5 person(s) detected | Inference time: 13.13 ms\n",
      "Frame 528: 5 person(s) detected | Inference time: 13.90 ms\n",
      "Frame 529: 5 person(s) detected | Inference time: 10.83 ms\n",
      "Frame 530: 5 person(s) detected | Inference time: 13.39 ms\n",
      "Frame 531: 5 person(s) detected | Inference time: 15.32 ms\n",
      "Frame 532: 5 person(s) detected | Inference time: 15.90 ms\n",
      "Frame 533: 5 person(s) detected | Inference time: 16.53 ms\n",
      "Frame 534: 5 person(s) detected | Inference time: 15.65 ms\n",
      "Frame 535: 6 person(s) detected | Inference time: 15.82 ms\n",
      "Frame 536: 6 person(s) detected | Inference time: 15.42 ms\n",
      "Frame 537: 6 person(s) detected | Inference time: 13.91 ms\n",
      "Frame 538: 5 person(s) detected | Inference time: 16.26 ms\n",
      "Frame 539: 5 person(s) detected | Inference time: 16.83 ms\n",
      "Frame 540: 6 person(s) detected | Inference time: 22.53 ms\n",
      "Frame 541: 6 person(s) detected | Inference time: 20.74 ms\n",
      "Frame 542: 6 person(s) detected | Inference time: 13.89 ms\n",
      "Frame 543: 5 person(s) detected | Inference time: 16.00 ms\n",
      "Frame 544: 6 person(s) detected | Inference time: 14.54 ms\n",
      "Frame 545: 6 person(s) detected | Inference time: 14.61 ms\n",
      "Frame 546: 6 person(s) detected | Inference time: 13.44 ms\n",
      "Frame 547: 5 person(s) detected | Inference time: 11.42 ms\n",
      "Frame 548: 5 person(s) detected | Inference time: 12.99 ms\n",
      "Frame 549: 5 person(s) detected | Inference time: 12.96 ms\n",
      "Frame 550: 5 person(s) detected | Inference time: 13.51 ms\n",
      "Frame 551: 5 person(s) detected | Inference time: 16.90 ms\n",
      "Frame 552: 5 person(s) detected | Inference time: 13.53 ms\n",
      "Frame 553: 5 person(s) detected | Inference time: 13.08 ms\n",
      "Frame 554: 5 person(s) detected | Inference time: 12.55 ms\n",
      "Frame 555: 5 person(s) detected | Inference time: 12.20 ms\n",
      "Frame 556: 5 person(s) detected | Inference time: 16.76 ms\n",
      "Frame 557: 6 person(s) detected | Inference time: 16.45 ms\n",
      "Frame 558: 6 person(s) detected | Inference time: 15.23 ms\n",
      "Frame 559: 6 person(s) detected | Inference time: 12.83 ms\n",
      "Frame 560: 6 person(s) detected | Inference time: 13.87 ms\n",
      "Frame 561: 6 person(s) detected | Inference time: 12.47 ms\n",
      "Frame 562: 7 person(s) detected | Inference time: 13.06 ms\n",
      "Frame 563: 7 person(s) detected | Inference time: 18.03 ms\n",
      "Frame 564: 7 person(s) detected | Inference time: 12.14 ms\n",
      "Frame 565: 7 person(s) detected | Inference time: 13.42 ms\n",
      "Frame 566: 7 person(s) detected | Inference time: 15.02 ms\n",
      "Frame 567: 7 person(s) detected | Inference time: 12.06 ms\n",
      "Frame 568: 7 person(s) detected | Inference time: 10.69 ms\n",
      "Frame 569: 7 person(s) detected | Inference time: 13.36 ms\n",
      "Frame 570: 7 person(s) detected | Inference time: 26.34 ms\n",
      "Frame 571: 7 person(s) detected | Inference time: 19.96 ms\n",
      "Frame 572: 7 person(s) detected | Inference time: 12.97 ms\n",
      "Frame 573: 7 person(s) detected | Inference time: 13.48 ms\n",
      "Frame 574: 6 person(s) detected | Inference time: 11.73 ms\n",
      "Frame 575: 6 person(s) detected | Inference time: 12.77 ms\n",
      "Frame 576: 6 person(s) detected | Inference time: 12.65 ms\n",
      "Frame 577: 5 person(s) detected | Inference time: 13.60 ms\n",
      "Frame 578: 5 person(s) detected | Inference time: 12.60 ms\n",
      "Frame 579: 5 person(s) detected | Inference time: 12.81 ms\n",
      "Frame 580: 5 person(s) detected | Inference time: 14.69 ms\n",
      "Frame 581: 5 person(s) detected | Inference time: 12.55 ms\n",
      "Frame 582: 6 person(s) detected | Inference time: 13.73 ms\n",
      "Frame 583: 6 person(s) detected | Inference time: 12.48 ms\n",
      "Frame 584: 6 person(s) detected | Inference time: 11.18 ms\n",
      "Frame 585: 6 person(s) detected | Inference time: 14.50 ms\n",
      "Frame 586: 6 person(s) detected | Inference time: 16.31 ms\n",
      "Frame 587: 7 person(s) detected | Inference time: 11.90 ms\n",
      "Frame 588: 7 person(s) detected | Inference time: 12.03 ms\n",
      "Frame 589: 6 person(s) detected | Inference time: 10.91 ms\n",
      "Frame 590: 6 person(s) detected | Inference time: 13.38 ms\n",
      "Frame 591: 6 person(s) detected | Inference time: 11.87 ms\n",
      "Frame 592: 6 person(s) detected | Inference time: 13.18 ms\n",
      "Frame 593: 6 person(s) detected | Inference time: 12.46 ms\n",
      "Frame 594: 6 person(s) detected | Inference time: 12.45 ms\n",
      "Frame 595: 6 person(s) detected | Inference time: 16.32 ms\n",
      "Frame 596: 6 person(s) detected | Inference time: 16.81 ms\n",
      "Frame 597: 6 person(s) detected | Inference time: 14.45 ms\n",
      "Frame 598: 6 person(s) detected | Inference time: 12.56 ms\n",
      "Frame 599: 6 person(s) detected | Inference time: 12.88 ms\n",
      "Frame 600: 6 person(s) detected | Inference time: 11.40 ms\n",
      "Frame 601: 6 person(s) detected | Inference time: 11.60 ms\n",
      "Frame 602: 6 person(s) detected | Inference time: 11.59 ms\n",
      "Frame 603: 5 person(s) detected | Inference time: 14.33 ms\n",
      "Frame 604: 5 person(s) detected | Inference time: 12.25 ms\n",
      "Frame 605: 5 person(s) detected | Inference time: 15.22 ms\n",
      "Frame 606: 5 person(s) detected | Inference time: 14.59 ms\n",
      "Frame 607: 5 person(s) detected | Inference time: 11.96 ms\n",
      "Frame 608: 5 person(s) detected | Inference time: 13.02 ms\n",
      "Frame 609: 5 person(s) detected | Inference time: 17.62 ms\n",
      "Frame 610: 5 person(s) detected | Inference time: 14.03 ms\n",
      "Frame 611: 5 person(s) detected | Inference time: 17.41 ms\n",
      "Frame 612: 5 person(s) detected | Inference time: 13.11 ms\n",
      "Frame 613: 5 person(s) detected | Inference time: 14.87 ms\n",
      "Frame 614: 5 person(s) detected | Inference time: 14.45 ms\n",
      "Frame 615: 4 person(s) detected | Inference time: 19.27 ms\n",
      "Frame 616: 4 person(s) detected | Inference time: 13.18 ms\n",
      "Frame 617: 4 person(s) detected | Inference time: 15.53 ms\n",
      "Frame 618: 4 person(s) detected | Inference time: 19.17 ms\n",
      "Frame 619: 4 person(s) detected | Inference time: 16.83 ms\n",
      "Frame 620: 5 person(s) detected | Inference time: 17.42 ms\n",
      "Frame 621: 5 person(s) detected | Inference time: 18.25 ms\n",
      "Frame 622: 5 person(s) detected | Inference time: 19.67 ms\n",
      "Frame 623: 5 person(s) detected | Inference time: 18.93 ms\n",
      "Frame 624: 5 person(s) detected | Inference time: 18.38 ms\n",
      "Frame 625: 5 person(s) detected | Inference time: 13.59 ms\n",
      "Frame 626: 5 person(s) detected | Inference time: 12.37 ms\n",
      "Frame 627: 5 person(s) detected | Inference time: 14.43 ms\n",
      "Frame 628: 5 person(s) detected | Inference time: 13.05 ms\n",
      "Frame 629: 6 person(s) detected | Inference time: 15.37 ms\n",
      "Frame 630: 4 person(s) detected | Inference time: 13.50 ms\n",
      "Frame 631: 5 person(s) detected | Inference time: 15.48 ms\n",
      "Frame 632: 5 person(s) detected | Inference time: 14.17 ms\n",
      "Frame 633: 5 person(s) detected | Inference time: 13.69 ms\n",
      "Frame 634: 5 person(s) detected | Inference time: 15.50 ms\n",
      "Frame 635: 6 person(s) detected | Inference time: 18.52 ms\n",
      "Frame 636: 6 person(s) detected | Inference time: 16.91 ms\n",
      "Frame 637: 5 person(s) detected | Inference time: 11.97 ms\n",
      "Frame 638: 5 person(s) detected | Inference time: 13.32 ms\n",
      "Frame 639: 5 person(s) detected | Inference time: 12.92 ms\n",
      "Frame 640: 5 person(s) detected | Inference time: 16.51 ms\n",
      "Frame 641: 5 person(s) detected | Inference time: 15.63 ms\n",
      "Frame 642: 5 person(s) detected | Inference time: 17.13 ms\n",
      "Frame 643: 4 person(s) detected | Inference time: 12.61 ms\n",
      "Frame 644: 5 person(s) detected | Inference time: 15.70 ms\n",
      "Frame 645: 5 person(s) detected | Inference time: 12.40 ms\n",
      "Frame 646: 5 person(s) detected | Inference time: 13.91 ms\n",
      "Frame 647: 5 person(s) detected | Inference time: 11.74 ms\n",
      "Frame 648: 6 person(s) detected | Inference time: 12.33 ms\n",
      "Frame 649: 6 person(s) detected | Inference time: 13.09 ms\n",
      "Frame 650: 5 person(s) detected | Inference time: 12.87 ms\n",
      "Frame 651: 5 person(s) detected | Inference time: 12.81 ms\n",
      "Frame 652: 5 person(s) detected | Inference time: 19.71 ms\n",
      "Frame 653: 5 person(s) detected | Inference time: 14.39 ms\n",
      "Frame 654: 6 person(s) detected | Inference time: 14.26 ms\n",
      "Frame 655: 5 person(s) detected | Inference time: 19.79 ms\n",
      "Frame 656: 5 person(s) detected | Inference time: 10.96 ms\n",
      "Frame 657: 5 person(s) detected | Inference time: 15.07 ms\n",
      "Frame 658: 5 person(s) detected | Inference time: 13.51 ms\n",
      "Frame 659: 5 person(s) detected | Inference time: 12.07 ms\n",
      "Frame 660: 5 person(s) detected | Inference time: 14.30 ms\n",
      "Frame 661: 5 person(s) detected | Inference time: 10.82 ms\n",
      "Frame 662: 5 person(s) detected | Inference time: 13.36 ms\n",
      "Frame 663: 5 person(s) detected | Inference time: 13.47 ms\n",
      "Frame 664: 5 person(s) detected | Inference time: 11.79 ms\n",
      "Frame 665: 5 person(s) detected | Inference time: 19.00 ms\n",
      "Frame 666: 5 person(s) detected | Inference time: 14.22 ms\n",
      "Frame 667: 5 person(s) detected | Inference time: 14.00 ms\n",
      "Frame 668: 5 person(s) detected | Inference time: 11.44 ms\n",
      "Frame 669: 5 person(s) detected | Inference time: 13.13 ms\n",
      "Frame 670: 5 person(s) detected | Inference time: 14.67 ms\n",
      "Frame 671: 6 person(s) detected | Inference time: 17.97 ms\n",
      "Frame 672: 6 person(s) detected | Inference time: 18.11 ms\n",
      "Frame 673: 6 person(s) detected | Inference time: 11.01 ms\n",
      "Frame 674: 6 person(s) detected | Inference time: 13.81 ms\n",
      "Frame 675: 6 person(s) detected | Inference time: 12.61 ms\n",
      "Frame 676: 5 person(s) detected | Inference time: 13.54 ms\n",
      "Frame 677: 6 person(s) detected | Inference time: 16.37 ms\n",
      "Frame 678: 5 person(s) detected | Inference time: 13.62 ms\n",
      "Frame 679: 5 person(s) detected | Inference time: 13.84 ms\n",
      "Frame 680: 5 person(s) detected | Inference time: 13.83 ms\n",
      "Frame 681: 5 person(s) detected | Inference time: 14.61 ms\n",
      "Frame 682: 6 person(s) detected | Inference time: 12.20 ms\n",
      "Frame 683: 6 person(s) detected | Inference time: 12.45 ms\n",
      "Frame 684: 6 person(s) detected | Inference time: 13.19 ms\n",
      "Frame 685: 6 person(s) detected | Inference time: 15.79 ms\n",
      "Frame 686: 6 person(s) detected | Inference time: 14.04 ms\n",
      "\n",
      "=== Performance Metrics ===\n",
      "Total frames processed: 686\n",
      "Total persons detected: 3439\n",
      "Total processing time: 19.30 seconds\n",
      "Average FPS (overall): 35.55\n",
      "Average inference time per frame: 16.01 ms\n",
      "Average confidence score: 0.829\n",
      "Output video saved to: output.mp4\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from ultralytics.utils.plotting import Annotator\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "class YOLOv8PersonDetector:\n",
    "    def __init__(self, model_path=\"yolov8n.pt\", device=\"cpu\"):\n",
    "        self.device = device\n",
    "        self.model = YOLO(model_path).to(device)\n",
    "        self.classes_to_detect = [0]  # Only \"person\" class\n",
    "\n",
    "    def process_frame(self, frame, conf_threshold=0.5):\n",
    "        start_infer = time.time()\n",
    "        results = self.model.predict(source=frame, conf=conf_threshold, device=self.device, classes=self.classes_to_detect, verbose=False)\n",
    "        end_infer = time.time()\n",
    "        inference_time = end_infer - start_infer  # in seconds\n",
    "\n",
    "        boxes = results[0].boxes\n",
    "        annotator = Annotator(frame, line_width=2)\n",
    "        person_count = 0\n",
    "        confidence_sum = 0.0\n",
    "\n",
    "        if boxes is not None and boxes.xyxy is not None:\n",
    "            for box in boxes:\n",
    "                conf = float(box.conf[0])\n",
    "                if conf < conf_threshold:\n",
    "                    continue\n",
    "                person_count += 1\n",
    "                confidence_sum += conf\n",
    "                annotator.box_label(box.xyxy[0].tolist(), label=f\"Person {conf:.2f}\", color=(255, 0, 0))\n",
    "\n",
    "        return annotator.result(), person_count, confidence_sum, person_count, inference_time\n",
    "\n",
    "def detect_person_in_video(input_path, output_path=\"output.mp4\", device=\"cpu\"):\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out_video = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "    detector = YOLOv8PersonDetector(device=device)\n",
    "\n",
    "    frame_count = 0\n",
    "    total_persons = 0\n",
    "    total_confidence = 0.0\n",
    "    total_detections = 0\n",
    "    total_inference_time = 0.0\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        processed_frame, person_count, conf_sum, det_count, infer_time = detector.process_frame(frame)\n",
    "        out_video.write(processed_frame)\n",
    "\n",
    "        frame_count += 1\n",
    "        total_persons += person_count\n",
    "        total_confidence += conf_sum\n",
    "        total_detections += det_count\n",
    "        total_inference_time += infer_time\n",
    "\n",
    "        print(f\"Frame {frame_count}: {person_count} person(s) detected | Inference time: {infer_time*1000:.2f} ms\")\n",
    "\n",
    "    cap.release()\n",
    "    out_video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    avg_fps = frame_count / total_time if total_time > 0 else 0\n",
    "    avg_infer_time = (total_inference_time / frame_count) * 1000 if frame_count > 0 else 0  # in ms\n",
    "    avg_confidence = total_confidence / total_detections if total_detections > 0 else 0.0\n",
    "\n",
    "    # Final metrics\n",
    "    print(\"\\n=== Performance Metrics ===\")\n",
    "    print(f\"Total frames processed: {frame_count}\")\n",
    "    print(f\"Total persons detected: {total_persons}\")\n",
    "    print(f\"Total processing time: {total_time:.2f} seconds\")\n",
    "    print(f\"Average FPS (overall): {avg_fps:.2f}\")\n",
    "    print(f\"Average inference time per frame: {avg_infer_time:.2f} ms\")\n",
    "    print(f\"Average confidence score: {avg_confidence:.3f}\")\n",
    "    print(f\"Output video saved to: {output_path}\")\n",
    "\n",
    "# Example usage:\n",
    "detect_person_in_video(\"test_video.mp4\", output_path=\"output.mp4\", device=\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f981ac1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4425514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.168 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 3768MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolo11n.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (5.4 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.61...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 1.2s, saved as 'yolo11n.onnx' (10.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m starting export with TensorRT 10.12.0.36...\n",
      "[07/22/2025-21:14:32] [TRT] [I] [MemUsageChange] Init CUDA: CPU -2, GPU +0, now: CPU 774, GPU 992 (MiB)\n",
      "[07/22/2025-21:14:35] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +1562, GPU -1, now: CPU 2487, GPU 990 (MiB)\n",
      "[07/22/2025-21:14:35] [TRT] [I] ----------------------------------------------------------------\n",
      "[07/22/2025-21:14:35] [TRT] [I] Input filename:   yolo11n.onnx\n",
      "[07/22/2025-21:14:35] [TRT] [I] ONNX IR version:  0.0.9\n",
      "[07/22/2025-21:14:35] [TRT] [I] Opset version:    19\n",
      "[07/22/2025-21:14:35] [TRT] [I] Producer name:    pytorch\n",
      "[07/22/2025-21:14:35] [TRT] [I] Producer version: 2.6.0\n",
      "[07/22/2025-21:14:35] [TRT] [I] Domain:           \n",
      "[07/22/2025-21:14:35] [TRT] [I] Model version:    0\n",
      "[07/22/2025-21:14:35] [TRT] [I] Doc string:       \n",
      "[07/22/2025-21:14:35] [TRT] [I] ----------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m input \"images\" with shape(1, 3, 640, 640) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m output \"output0\" with shape(1, 84, 8400) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m building FP16 engine as yolo11n.engine\n",
      "[07/22/2025-21:14:35] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[07/22/2025-21:16:22] [TRT] [I] Compiler backend is used during engine build.\n",
      "[07/22/2025-21:18:33] [TRT] [I] Detected 1 inputs and 1 output network tensors.\n",
      "[07/22/2025-21:18:35] [TRT] [I] Total Host Persistent Memory: 539664 bytes\n",
      "[07/22/2025-21:18:35] [TRT] [I] Total Device Persistent Memory: 1024 bytes\n",
      "[07/22/2025-21:18:35] [TRT] [I] Max Scratch Memory: 1382400 bytes\n",
      "[07/22/2025-21:18:35] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 172 steps to complete.\n",
      "[07/22/2025-21:18:35] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 8.14386ms to assign 11 blocks to 172 nodes requiring 10138624 bytes.\n",
      "[07/22/2025-21:18:35] [TRT] [I] Total Activation Memory: 10137600 bytes\n",
      "[07/22/2025-21:18:35] [TRT] [I] Total Weights Memory: 5316610 bytes\n",
      "[07/22/2025-21:18:35] [TRT] [I] Compiler backend is used during engine execution.\n",
      "[07/22/2025-21:18:35] [TRT] [I] Engine generation completed in 240.103 seconds.\n",
      "[07/22/2025-21:18:35] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 0 MiB, GPU 261 MiB\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m export success ✅ 244.4s, saved as 'yolo11n.engine' (9.4 MB)\n",
      "\n",
      "Export complete (245.1s)\n",
      "Results saved to \u001b[1m/home/ika1/yzlm/Re-id/object_detection_Re-ID/YOLO\u001b[0m\n",
      "Predict:         yolo predict task=detect model=yolo11n.engine imgsz=640 half \n",
      "Validate:        yolo val task=detect model=yolo11n.engine imgsz=640 data=/usr/src/ultralytics/ultralytics/cfg/datasets/coco.yaml half \n",
      "Visualize:       https://netron.app\n",
      "💡 Learn more at https://docs.ultralytics.com/modes/export\n"
     ]
    }
   ],
   "source": [
    "!yolo export model=yolo11n.pt format=engine device=0 half=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d775870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Detector initialized with model: yolo11n.engine on device: cuda\n",
      "🚀 Running with batch size: 1\n",
      "Loading yolo11n.engine for TensorRT inference...\n",
      "[07/22/2025-21:18:53] [TRT] [I] Loaded engine size: 9 MiB\n",
      "[07/22/2025-21:18:53] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +9, now: CPU 0, GPU 14 (MiB)\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 77.14 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 10.73 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.39 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.22 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.68 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.50 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 10.94 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.41 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.87 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.82 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.65 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.79 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.16 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.52 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.19 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.35 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.88 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.88 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.95 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.66 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.83 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 10.44 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.02 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.58 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.43 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.35 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.88 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.66 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.48 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.38 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.25 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.46 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.33 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.16 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.37 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.17 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.52 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 10.31 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.40 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.58 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.93 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.90 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.09 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.37 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.70 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.94 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 10.97 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.07 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 10.53 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.55 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.30 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.27 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.31 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.14 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.18 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.09 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.40 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.46 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.53 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.09 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.33 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.37 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.23 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.04 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.66 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.87 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.96 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.88 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.16 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.10 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.04 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.32 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.83 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.30 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.49 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.17 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.90 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.04 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.19 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.19 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.32 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.29 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.78 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.60 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.27 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.42 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.48 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.68 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.98 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.93 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.53 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.66 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.14 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.32 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.33 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.00 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.07 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.94 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.45 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.18 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.65 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.18 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.02 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.28 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.83 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.47 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.00 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.85 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.06 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.35 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.32 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.59 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.73 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.26 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.32 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.06 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.10 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.58 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.49 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.28 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.60 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 10.33 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.76 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.56 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.36 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.02 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.99 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.83 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.40 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.59 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.18 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.79 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.93 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.50 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.09 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.64 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.06 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.10 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.16 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.69 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.33 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.19 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.69 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.17 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.87 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.02 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.15 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.45 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.60 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.53 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.85 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.38 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.47 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.38 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.80 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.04 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.91 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.92 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.05 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.07 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.23 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.52 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.37 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.33 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.01 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.02 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.47 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.35 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.91 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.26 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.51 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.62 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.73 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.02 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.87 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.09 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.10 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.03 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.49 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 10.32 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.44 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.27 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.95 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.29 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.86 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.10 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.33 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.59 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.19 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.15 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.76 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.24 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.00 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.97 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.10 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.39 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.75 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.06 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.59 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.29 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.00 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.37 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.93 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.93 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.77 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.38 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.05 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.28 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.27 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.54 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.47 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.12 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.20 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.07 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.39 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 10.01 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.46 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.47 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.26 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.27 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.09 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.17 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.70 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.37 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.04 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.91 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.16 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.34 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.34 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.47 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.33 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.31 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.96 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.22 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.53 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.90 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.83 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.71 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.00 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.06 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.29 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.47 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.57 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.71 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.68 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.87 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.07 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.00 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.81 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.09 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.39 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.18 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.29 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.67 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.31 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.07 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.50 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.36 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.78 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.86 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.76 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.63 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.31 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.25 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.46 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.51 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.76 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.88 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.27 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.15 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.11 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.62 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.06 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.41 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.11 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.73 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.89 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.25 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.31 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.15 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.92 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.52 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.27 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.02 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.83 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.28 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.24 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.31 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.71 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.55 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.17 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.67 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 10.06 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.84 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.25 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.85 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.41 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.19 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.45 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.61 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.41 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.13 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.20 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.02 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.12 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.04 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.25 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.36 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.23 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.32 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.13 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.01 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.10 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.19 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.49 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.56 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.13 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.32 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.17 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.18 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.17 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.36 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.53 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.01 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.26 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.34 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.97 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.19 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.30 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.76 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.33 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.12 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.61 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.50 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.54 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.75 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.50 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.76 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.22 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.75 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.70 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.51 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.01 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.50 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.18 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.21 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.05 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 10.11 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 13.30 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.06 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.90 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.17 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.17 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.30 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.66 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.35 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.14 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.97 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.18 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.61 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.25 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.40 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.14 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.70 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.12 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.14 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.17 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.63 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.19 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.91 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.76 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.14 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.22 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.75 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.72 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.09 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.32 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.27 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.14 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.30 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.69 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.80 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.38 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.47 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.45 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.94 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.28 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.38 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.18 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.57 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.62 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.62 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.91 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.45 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.17 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.55 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.44 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.57 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.63 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.28 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.28 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.06 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.15 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.82 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.14 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.24 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.38 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.13 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.33 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.04 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.58 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.65 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.11 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.37 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.63 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.15 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.07 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.28 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.77 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.12 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.98 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.58 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.95 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.98 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.14 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.58 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.54 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.98 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.50 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.33 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.33 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.32 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.21 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.26 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.09 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.57 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.40 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.76 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.06 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.81 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.04 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.38 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.74 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.51 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.35 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.90 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.14 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.95 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.40 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.95 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.62 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.16 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.16 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.02 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.96 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.50 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.86 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.46 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.28 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.00 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.74 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.93 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.12 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.62 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.25 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.49 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.70 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.84 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.07 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.65 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.20 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.73 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.67 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.42 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.59 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.23 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.27 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.95 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.13 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.90 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.81 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.63 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.02 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.47 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.73 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.49 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.70 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.07 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.05 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.00 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.09 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.61 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.92 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.77 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.86 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.04 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 10.02 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.79 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.22 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.82 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.27 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.13 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.24 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.85 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.58 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.34 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.11 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.24 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.69 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.99 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.62 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.16 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.94 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.69 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.76 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.28 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.57 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 10.28 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.16 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.01 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.07 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.19 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.36 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.51 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.06 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.54 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.22 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.15 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.55 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.52 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.14 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.15 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.12 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.17 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.36 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.25 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.09 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.20 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.95 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.26 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.27 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.55 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.97 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.80 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.09 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.27 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.57 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.74 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.23 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.74 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.34 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.33 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.15 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.10 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.36 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.91 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.29 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.13 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.22 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.58 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.34 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.31 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.11 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.10 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.76 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.44 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.03 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.12 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.68 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.18 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.09 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.77 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.60 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.32 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.30 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.87 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.92 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.23 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.30 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.12 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.38 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.25 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.14 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.12 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.15 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.61 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.93 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.15 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.87 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.41 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.09 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.57 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.47 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.41 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.89 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.11 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.06 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.85 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.92 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.85 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.39 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.04 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.08 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.15 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.76 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.45 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.19 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.09 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.16 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.43 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.49 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.26 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.08 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.91 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.05 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.33 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.08 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.45 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.95 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.58 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.57 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 11.44 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.95 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.08 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.67 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.10 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.15 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.29 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.96 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.94 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 10.76 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.96 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 10.08 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.72 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.16 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.98 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.89 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.40 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.72 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.03 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.22 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.83 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.02 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.82 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.32 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.20 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.07 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.77 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.43 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.55 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.15 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.19 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.51 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.60 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.55 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.58 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.06 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.19 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.62 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.97 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.88 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.89 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.80 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.06 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.31 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.30 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.24 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.58 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.60 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.69 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.03 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.10 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.10 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.54 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.38 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.47 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 5.88 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.00 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 8.44 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 9.53 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.22 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.14 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.19 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.12 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 6.23 ms\n",
      "Processed Batch of 1 frames | Avg Inference per frame: 7.99 ms\n",
      "\n",
      "🚀 === Final Performance Metrics (Optimized) ===\n",
      "Total frames processed: 686\n",
      "Total persons detected: 3552\n",
      "Total processing time: 10.81 seconds\n",
      "Average FPS (overall throughput): 63.47\n",
      "Average inference time per frame: 7.36 ms\n",
      "Average confidence score: 0.835\n",
      "Output video saved to: output_fp16_v12.mp4\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from ultralytics.utils.plotting import Annotator\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "class YOLOv8PersonDetector:\n",
    "    def __init__(self, model_path=\"yolov8n.engine\", device=\"cuda\"):\n",
    "        self.device = device\n",
    "        self.model = YOLO(model_path)\n",
    "\n",
    "    def process_batch(self, frames_batch, conf_threshold=0.5):\n",
    "        \"\"\"Processes a batch of frames for person detection.\"\"\"\n",
    "        start_infer = time.time()\n",
    "        \n",
    "        # Predict on the entire batch of frames at once\n",
    "        results_list = self.model.predict(source=frames_batch, conf=conf_threshold, device=self.device, classes=0, verbose=False)\n",
    "        \n",
    "        end_infer = time.time()\n",
    "        inference_time_for_batch = end_infer - start_infer\n",
    "\n",
    "        processed_frames = []\n",
    "        total_persons_in_batch = 0\n",
    "        total_confidence_in_batch = 0.0\n",
    "        total_detections_in_batch = 0\n",
    "\n",
    "        # Iterate through the results for each frame in the batch\n",
    "        for i, results in enumerate(results_list):\n",
    "            original_frame = frames_batch[i]\n",
    "            annotator = Annotator(original_frame.copy(), line_width=2)\n",
    "            \n",
    "            boxes = results.boxes\n",
    "            person_count = 0\n",
    "            confidence_sum = 0.0\n",
    "\n",
    "            if boxes is not None and boxes.xyxy is not None:\n",
    "                for box in boxes:\n",
    "                    conf = float(box.conf[0])\n",
    "                    person_count += 1\n",
    "                    confidence_sum += conf\n",
    "                    annotator.box_label(box.xyxy[0].tolist(), label=f\"Person {conf:.2f}\", color=(0, 255, 0))\n",
    "\n",
    "            processed_frames.append(annotator.result())\n",
    "            total_persons_in_batch += person_count\n",
    "            total_confidence_in_batch += confidence_sum\n",
    "            total_detections_in_batch += person_count\n",
    "\n",
    "        return processed_frames, total_persons_in_batch, total_confidence_in_batch, total_detections_in_batch, inference_time_for_batch\n",
    "\n",
    "def detect_person_in_video(model_path, input_path, output_path=\"output_optimized.mp4\", device=\"cuda\", batch_size=4):\n",
    "    \"\"\"Processes a video using batch inference for higher throughput.\"\"\"\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out_video = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "    detector = YOLOv8PersonDetector(model_path=model_path, device=device)\n",
    "    print(f\"✅ Detector initialized with model: {model_path} on device: {device}\")\n",
    "    print(f\"🚀 Running with batch size: {batch_size}\")\n",
    "\n",
    "\n",
    "    frame_count = 0\n",
    "    total_persons = 0\n",
    "    total_confidence = 0.0\n",
    "    total_detections = 0\n",
    "    total_inference_time = 0.0\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Main loop to read and process frames in batches\n",
    "    while True:\n",
    "        frames_batch = []\n",
    "        for _ in range(batch_size):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frames_batch.append(frame)\n",
    "\n",
    "        # If the batch is empty, we've reached the end of the video\n",
    "        if not frames_batch:\n",
    "            break\n",
    "\n",
    "        # Process the entire batch\n",
    "        processed_frames, persons, conf_sum, dets, infer_time = detector.process_batch(frames_batch)\n",
    "        \n",
    "        # Write processed frames to the output video\n",
    "        for p_frame in processed_frames:\n",
    "            out_video.write(p_frame)\n",
    "\n",
    "        # Update statistics\n",
    "        num_frames_in_batch = len(frames_batch)\n",
    "        frame_count += num_frames_in_batch\n",
    "        total_persons += persons\n",
    "        total_confidence += conf_sum\n",
    "        total_detections += dets\n",
    "        total_inference_time += infer_time\n",
    "\n",
    "        avg_time_per_frame = (infer_time / num_frames_in_batch) * 1000\n",
    "        print(f\"Processed Batch of {num_frames_in_batch} frames | Avg Inference per frame: {avg_time_per_frame:.2f} ms\")\n",
    "\n",
    "    cap.release()\n",
    "    out_video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    avg_fps = frame_count / total_time if total_time > 0 else 0\n",
    "    avg_infer_time = (total_inference_time / frame_count) * 1000 if frame_count > 0 else 0\n",
    "    avg_confidence = total_confidence / total_detections if total_detections > 0 else 0.0\n",
    "\n",
    "    print(\"\\n🚀 === Final Performance Metrics (Optimized) ===\")\n",
    "    print(f\"Total frames processed: {frame_count}\")\n",
    "    print(f\"Total persons detected: {total_persons}\")\n",
    "    print(f\"Total processing time: {total_time:.2f} seconds\")\n",
    "    print(f\"Average FPS (overall throughput): {avg_fps:.2f}\")\n",
    "    print(f\"Average inference time per frame: {avg_infer_time:.2f} ms\")\n",
    "    print(f\"Average confidence score: {avg_confidence:.3f}\")\n",
    "    print(f\"Output video saved to: {output_path}\")\n",
    "\n",
    "# --- HOW TO RUN ---\n",
    "if __name__ == '__main__':\n",
    "    # 1. First, export the model with the 'half=True' flag as shown above.\n",
    "    # 2. Update the path to your new FP16 engine file.\n",
    "    \n",
    "    ENGINE_MODEL_PATH = \"yolo11n.engine\"  # <-- Use your new FP16 .engine file\n",
    "    INPUT_VIDEO_PATH = \"test_video.mp4\"\n",
    "    OUTPUT_VIDEO_PATH = \"output_fp16_v12.mp4\"\n",
    "    DEVICE = \"cuda\"\n",
    "    \n",
    "    # Adjust batch size based on your GPU's VRAM. Start with 4 or 8.\n",
    "    BATCH_SIZE = 1\n",
    "\n",
    "    detect_person_in_video(\n",
    "        model_path=ENGINE_MODEL_PATH,\n",
    "        input_path=INPUT_VIDEO_PATH,\n",
    "        output_path=OUTPUT_VIDEO_PATH,\n",
    "        device=DEVICE,\n",
    "        batch_size=BATCH_SIZE\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
